#!/usr/bin/env node

/**
 * Enhanced RSS Crawler Script voor Nonbulla
 * 
 * Test de geavanceerde RSS crawler met story clustering
 * 
 * Gebruik:
 * node scripts/enhanced-crawl.js
 * node scripts/enhanced-crawl.js status
 * 
 * Of via npm:
 * npm run enhanced-crawl
 * npm run enhanced-crawl:status
 */

const fetch = (...args) => import('node-fetch').then(({default: fetch}) => fetch(...args))

async function runEnhancedCrawl() {
  const apiUrl = process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'
  const apiKey = process.env.RSS_API_KEY || 'nonbulla-rss-key-2025'

  try {
    console.log('ğŸš€ Starting Enhanced RSS Crawl for Nonbulla...')
    console.log(`ğŸ“¡ API URL: ${apiUrl}`)
    console.log('â° This may take 30-60 seconds...\n')
    
    const startTime = Date.now()
    
    const response = await fetch(`${apiUrl}/api/crawler/enhanced`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      }
    })

    const duration = Date.now() - startTime

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`)
    }

    const result = await response.json()

    if (result.success) {
      console.log('âœ… Enhanced RSS Crawl completed successfully!\n')
      console.log('ğŸ“Š Crawl Results:')
      console.log(`   ğŸ•’ Duration: ${result.data.crawl_duration_ms}ms (API: ${duration}ms)`)
      console.log(`   ğŸ“° Primary articles found: ${result.data.primary_articles_count}`)
      console.log(`   ğŸ¯ Story clusters detected: ${result.data.story_clusters_found}`)
      console.log(`   âœ… Sources crawled successfully: ${result.data.sources_crawled}`)
      console.log(`   âŒ Sources failed: ${result.data.sources_failed}`)
      console.log(`   ğŸ“„ Total articles processed: ${result.data.total_articles}`)
      
      if (result.data.errors && result.data.errors.length > 0) {
        console.log(`\nâš ï¸  Errors encountered (${result.data.errors.length}):`)
        result.data.errors.forEach(error => console.log(`   - ${error}`))
      }

      console.log(`\nğŸ”— Timestamp: ${result.data.timestamp}`)
      
      // Show story clustering insights
      if (result.data.story_clusters_found > 0) {
        console.log(`\nğŸ§  Story Clustering Analysis:`)
        console.log(`   - Detected ${result.data.story_clusters_found} potential cross-source stories`)
        console.log(`   - This indicates ${result.data.story_clusters_found} topics covered by multiple sources`)
        console.log(`   - Ready for cross-reference analysis and unified article generation`)
      }
      
    } else {
      console.error('âŒ Enhanced RSS crawl failed:', result.error)
      console.error('Message:', result.message)
    }

  } catch (error) {
    console.error('âŒ Failed to run enhanced RSS crawl:', error.message)
    console.error('Stack:', error.stack)
    process.exit(1)
  }
}

async function checkCrawlerStatus() {
  const apiUrl = process.env.NEXT_PUBLIC_APP_URL || 'http://localhost:3000'

  try {
    console.log('ğŸ“Š Checking Enhanced RSS Crawler status...')
    
    const response = await fetch(`${apiUrl}/api/crawler/enhanced`)
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`)
    }

    const result = await response.json()

    if (result.success) {
      console.log('âœ… Enhanced RSS Crawler is operational\n')
      console.log('ğŸ“ˆ Crawler Configuration:')
      console.log(`   ğŸ“° Total sources configured: ${result.data.total_sources}`)
      console.log(`   ğŸ¯ Primary Dutch sources: ${result.data.primary_sources}`)
      
      console.log('\nğŸ“Š Sources by Tier:')
      console.log(`   ğŸ¥‡ Primary: ${result.data.sources_by_tier.primary} sources`)
      console.log(`   ğŸ¥ˆ Secondary: ${result.data.sources_by_tier.secondary} sources`)
      console.log(`   ğŸ­ Specialty: ${result.data.sources_by_tier.specialty} sources`)
      console.log(`   ğŸŒ International: ${result.data.sources_by_tier.international} sources`)

      console.log('\nğŸ¯ Primary Sources (Cross-Reference Required):')
      result.data.primary_source_names.forEach(name => {
        console.log(`   â€¢ ${name}`)
      })

      console.log(`\nğŸ”— Status checked at: ${result.data.last_status_check}`)
      
    } else {
      console.error('âŒ Crawler status check failed:', result.error)
    }

  } catch (error) {
    console.error('âŒ Failed to check crawler status:', error.message)
  }
}

// Main execution
if (require.main === module) {
  const command = process.argv[2]

  switch (command) {
    case 'status':
      checkCrawlerStatus()
      break
    case 'crawl':
    default:
      runEnhancedCrawl()
      break
  }
}

module.exports = { runEnhancedCrawl, checkCrawlerStatus }